{
  "displayName": "Unify Chat Provider",
  "description": "Integrate multiple LLM API providers into VS Code's GitHub Copilot Chat using the Language Model API.",
  "languageModelChatProviders.displayName": "Unify Chat Provider",
  "command.addProvider.title": "Unify Chat Provider: Add Provider",
  "command.removeProvider.title": "Unify Chat Provider: Remove Provider",
  "command.importConfig.title": "Unify Chat Provider: Import Config",
  "command.addProviderFromWellKnownProviderList.title": "Unify Chat Provider: Add Provider From Well-Known Provider List",
  "command.importConfigFromOtherApplications.title": "Unify Chat Provider: Import Config From Other Applications",
  "command.exportConfig.title": "Unify Chat Provider: Export Config",
  "command.manageProviders.title": "Unify Chat Provider: Manage Providers",
  "command.refreshAllProvidersOfficialModels.title": "Unify Chat Provider: Refresh All Provider's Official Models",
  "command.refreshAllProvidersBalance.title": "Unify Chat Provider: Refresh All Providers' Balance Information",
  "configuration.title": "Unify Chat Provider",
  "configuration.verbose.description": "Enable verbose logging of requests and responses.",
  "configuration.storeApiKeyInSettings.description": "Store sync-safe sensitive data (e.g., API keys) in settings.json instead of VS Code Secret Storage.\n\nOAuth credentials are always kept in Secret Storage to avoid multi-device token refresh conflicts.\n\nDANGER: Changing this setting will migrate existing data between storage locations (may expose secrets in plain text).",
  "configuration.balanceRefreshIntervalMs.description": "Periodic refresh interval for provider balances in milliseconds. Default: 60000 (60 seconds).",
  "configuration.balanceThrottleWindowMs.description": "Throttle window for post-request balance refresh in milliseconds. Default: 10000 (10 seconds).",
  "configuration.networkSettings.description": "Global network settings for chat requests.",
  "configuration.networkSettings.timeout.description": "Timeout settings for chat requests (milliseconds).",
  "configuration.networkSettings.timeout.connection.description": "TCP connection timeout in milliseconds (chat requests).",
  "configuration.networkSettings.timeout.response.description": "Maximum time between SSE data chunks in milliseconds (chat requests).",
  "configuration.networkSettings.retry.description": "Retry settings for chat requests.",
  "configuration.networkSettings.retry.maxRetries.description": "Maximum number of retry attempts for chat requests.",
  "configuration.networkSettings.retry.initialDelayMs.description": "Initial retry delay in milliseconds (chat requests).",
  "configuration.networkSettings.retry.maxDelayMs.description": "Maximum retry delay cap in milliseconds (chat requests).",
  "configuration.networkSettings.retry.backoffMultiplier.description": "Backoff multiplier for exponential retry delay (chat requests).",
  "configuration.networkSettings.retry.jitterFactor.description": "Jitter factor (0-1) to randomize retry delay (chat requests).",
  "configuration.endpoints.description": "List of LLM API provider endpoints.",
  "configuration.endpoints.type.description": "API format type. Determines how requests are formatted.",
  "configuration.endpoints.type.enumDescriptions.0": "Anthropic Messages API",
  "configuration.endpoints.type.enumDescriptions.1": "Google AI Studio (Gemini API)",
  "configuration.endpoints.type.enumDescriptions.2": "Google Vertex AI",
  "configuration.endpoints.type.enumDescriptions.3": "OpenAI Chat Completion API",
  "configuration.endpoints.type.enumDescriptions.4": "OpenAI Responses API",
  "configuration.endpoints.type.enumDescriptions.5": "Ollama Chat API",
  "configuration.endpoints.type.enumDescriptions.6": "Google Antigravity",
  "configuration.endpoints.type.enumDescriptions.7": "OpenAI Codex",
  "configuration.endpoints.type.enumDescriptions.8": "Google Gemini CLI",
  "configuration.endpoints.type.enumDescriptions.9": "Anthropic Claude Code",
  "configuration.endpoints.type.enumDescriptions.10": "GitHub Copilot",
  "configuration.endpoints.type.enumDescriptions.11": "Qwen Code",
  "configuration.endpoints.name.description": "Display name for this provider.",
  "configuration.endpoints.baseUrl.description": "API base URL (e.g., https://api.anthropic.com).",
  "configuration.endpoints.balanceProvider.description": "Provider balance monitoring configuration.",
  "configuration.endpoints.balanceProvider.method.none.description": "Disable balance monitoring.",
  "configuration.endpoints.balanceProvider.method.moonshot.description": "Use Moonshot AI balance monitor.",
  "configuration.endpoints.balanceProvider.method.kimiCode.description": "Use Kimi Code usage monitor.",
  "configuration.endpoints.balanceProvider.method.newapi.description": "Use New API balance monitor.",
  "configuration.endpoints.balanceProvider.newapi.userId.description": "New API user ID.",
  "configuration.endpoints.balanceProvider.newapi.systemToken.description": "New API system token.",
  "configuration.endpoints.extraHeaders.description": "Extra headers to include in requests. Header values support `${APIKEY}` to reference the provider credential.",
  "configuration.endpoints.extraBody.description": "Extra body parameters to include in requests.",
  "configuration.endpoints.timeout.description": "Timeout settings for chat requests (milliseconds).",
  "configuration.endpoints.timeout.connection.description": "TCP connection timeout in milliseconds (chat requests).",
  "configuration.endpoints.timeout.response.description": "Maximum time between SSE data chunks in milliseconds (chat requests).",
  "configuration.endpoints.retry.description": "Retry settings for chat requests (per-provider override).",
  "configuration.endpoints.retry.maxRetries.description": "Maximum number of retry attempts for chat requests.",
  "configuration.endpoints.retry.initialDelayMs.description": "Initial retry delay in milliseconds (chat requests).",
  "configuration.endpoints.retry.maxDelayMs.description": "Maximum retry delay cap in milliseconds (chat requests).",
  "configuration.endpoints.retry.backoffMultiplier.description": "Backoff multiplier for exponential retry delay (chat requests).",
  "configuration.endpoints.retry.jitterFactor.description": "Jitter factor (0-1) to randomize retry delay (chat requests).",
  "configuration.endpoints.autoFetchOfficialModels.description": "Automatically fetch and sync official models from the provider API.",
  "configuration.endpoints.models.description": "List of available models.",
  "configuration.endpoints.models.string.description": "Model ID",
  "configuration.endpoints.models.id.description": "Model ID (e.g., claude-sonnet-4-20250514).",
  "configuration.endpoints.models.name.description": "Display name for the model.",
  "configuration.endpoints.models.family.description": "Model family (e.g., gpt-4, claude-3). Defaults to model ID.",
  "configuration.endpoints.models.maxInputTokens.description": "Maximum input/context tokens.",
  "configuration.endpoints.models.maxOutputTokens.description": "Maximum output tokens.",
  "configuration.endpoints.models.tokenizer.description": "Tokenizer used for token counting in VS Code.",
  "configuration.endpoints.models.tokenizer.enumDescriptions.0": "Alias of char4. The approximate algorithm used by VS Code officially (about 4 characters per token).",
  "configuration.endpoints.models.tokenizer.enumDescriptions.1": "A conservative tokenizer based on UTF-8 bytes ensures that the modelâ€™s context limit is not exceeded, but it may trigger context compression more quickly due to significant deviations from actual token consumption.",
  "configuration.endpoints.models.tokenizer.enumDescriptions.2": "The approximate algorithm used by VS Code officially (about 4 characters per token).",
  "configuration.endpoints.models.tokenizer.enumDescriptions.3": "Tokenization powered by OpenAI tiktoken with model-aware encoding selection.",
  "configuration.endpoints.models.tokenizer.enumDescriptions.4": "Tokenization powered by DeepSeek official tokenizer files.",
  "configuration.endpoints.models.tokenCountMultiplier.description": "Multiplier applied to the token count before returning it to VS Code.",
  "configuration.endpoints.models.capabilities.description": "Model capabilities.",
  "configuration.endpoints.models.capabilities.toolCalling.boolean.description": "Whether the model supports tool/function calling.",
  "configuration.endpoints.models.capabilities.toolCalling.integer.description": "Maximum number of tools supported.",
  "configuration.endpoints.models.capabilities.imageInput.description": "Whether the model supports image input.",
  "configuration.endpoints.models.parallelToolCalling.description": "Enable or disable parallel tool calling (unset for provider default).",
  "configuration.endpoints.models.stream.description": "Whether to stream the response.",
  "configuration.endpoints.models.temperature.description": "Sampling temperature.",
  "configuration.endpoints.models.topK.description": "Top-k sampling.",
  "configuration.endpoints.models.topP.description": "Top-p sampling.",
  "configuration.endpoints.models.presencePenalty.description": "Presence penalty.",
  "configuration.endpoints.models.frequencyPenalty.description": "Frequency penalty.",
  "configuration.endpoints.models.verbosity.description": "Constrains response verbosity (low=concise, high=verbose).",
  "configuration.endpoints.models.verbosity.enumDescriptions.0": "More concise responses.",
  "configuration.endpoints.models.verbosity.enumDescriptions.1": "Balanced verbosity.",
  "configuration.endpoints.models.verbosity.enumDescriptions.2": "More verbose responses.",
  "configuration.endpoints.models.thinking.description": "Thinking configuration.",
  "configuration.endpoints.models.thinking.enabled.type.description": "Enable thinking.",
  "configuration.endpoints.models.thinking.enabled.budgetTokens.description": "Token budget for thinking.",
  "configuration.endpoints.models.thinking.enabled.effort.description": "Thinking effort level (leave blank to let the provider decide).",
  "configuration.endpoints.models.thinking.enabled.effort.enumDescriptions.0": "No thinking effort.",
  "configuration.endpoints.models.thinking.enabled.effort.enumDescriptions.1": "Minimal thinking effort.",
  "configuration.endpoints.models.thinking.enabled.effort.enumDescriptions.2": "Low thinking effort.",
  "configuration.endpoints.models.thinking.enabled.effort.enumDescriptions.3": "Medium thinking effort.",
  "configuration.endpoints.models.thinking.enabled.effort.enumDescriptions.4": "High thinking effort.",
  "configuration.endpoints.models.thinking.enabled.effort.enumDescriptions.5": "Extra high thinking effort.",
  "configuration.endpoints.models.thinking.auto.type.description": "Auto thinking.",
  "configuration.endpoints.models.thinking.auto.budgetTokens.description": "Token budget for thinking.",
  "configuration.endpoints.models.thinking.auto.effort.description": "Thinking effort level (leave blank to let the provider decide).",
  "configuration.endpoints.models.thinking.auto.effort.enumDescriptions.0": "No thinking effort.",
  "configuration.endpoints.models.thinking.auto.effort.enumDescriptions.1": "Minimal thinking effort.",
  "configuration.endpoints.models.thinking.auto.effort.enumDescriptions.2": "Low thinking effort.",
  "configuration.endpoints.models.thinking.auto.effort.enumDescriptions.3": "Medium thinking effort.",
  "configuration.endpoints.models.thinking.auto.effort.enumDescriptions.4": "High thinking effort.",
  "configuration.endpoints.models.thinking.auto.effort.enumDescriptions.5": "Extra high thinking effort.",
  "configuration.endpoints.models.thinking.disabled.type.description": "Disable thinking.",
  "configuration.endpoints.models.webSearch.description": "Use native web search tool.",
  "configuration.endpoints.models.webSearch.enabled.description": "Whether web search is enabled.",
  "configuration.endpoints.models.webSearch.maxUses.description": "Maximum number of web searches per request.",
  "configuration.endpoints.models.webSearch.allowedDomains.description": "Only include results from these domains.",
  "configuration.endpoints.models.webSearch.blockedDomains.description": "Never include results from these domains.",
  "configuration.endpoints.models.webSearch.userLocation.description": "User location for localizing search results.",
  "configuration.endpoints.models.webSearch.userLocation.type.description": "Approximate location.",
  "configuration.endpoints.models.webSearch.userLocation.city.description": "City.",
  "configuration.endpoints.models.webSearch.userLocation.region.description": "Region.",
  "configuration.endpoints.models.webSearch.userLocation.country.description": "Country.",
  "configuration.endpoints.models.webSearch.userLocation.timezone.description": "Timezone.",
  "configuration.endpoints.models.memoryTool.description": "Use native memory tool.",
  "configuration.endpoints.models.extraHeaders.description": "Extra headers to include in requests. Header values support `${APIKEY}` to reference the provider apiKey.",
  "configuration.endpoints.models.extraBody.description": "Extra body parameters to include in requests."
}
